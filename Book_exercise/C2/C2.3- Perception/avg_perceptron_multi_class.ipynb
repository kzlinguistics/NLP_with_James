{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label class \n",
    "\n",
    "#theta\n",
    "#theta_training_in_loop\n",
    "#theta_testing_in_loop\n",
    "#avg_weight\n",
    "\n",
    "################################\n",
    "#a function here on old code line 38 \n",
    "\n",
    "#for testing part- line 22. turn that into an argmax to generate \n",
    "# predicted label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelClass:\n",
    "    \n",
    "    #the constructor function, the things here WILL need to be give \n",
    "    #to even initialize the label class \n",
    "    def __init__(self, label, number_of_zeros_needed):\n",
    "        self.label = label \n",
    "        self.number_of_zeros_needed= number_of_zeros_needed\n",
    "\n",
    "        #initializing the things that need to happen \n",
    "        self.theta = np.zeros(number_of_zeros_needed)\n",
    "        self.running_total = np.zeros(number_of_zeros_needed)\n",
    "\n",
    "    #calc score for each label as an intermidiate value \n",
    "    def calc_score(self, x_vector):\n",
    "        return np.dot(x_vector, self.theta) \n",
    "    \n",
    "    #this is new- this is what we are using within loop throughout the loops \n",
    "    def update_running_total(self):\n",
    "        self.running_total+=self.theta\n",
    "    \n",
    "    #this is just a calculation \n",
    "    #once at the very end \n",
    "    def calc_avg_weight(self, count):\n",
    "        self.avg_weight= self.running_total/count\n",
    "\n",
    "\n",
    "    def calc_test_score(self,x_vector):\n",
    "        return np.dot(x_vector, self.avg_weight) \n",
    "\n",
    "\n",
    "    #this is gonna give you a true or false \n",
    "\n",
    "    #the label input here is the predicted label \n",
    "    def is_label(self, label):\n",
    "        return self.label == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_train  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'\n",
    "\n",
    "df_train = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "labels= ['true', \"false\", \"half-true\", \"barely-true\"]\n",
    "other_df = pd.DataFrame({\"label\": labels})\n",
    "\n",
    "df_linear = df_train[df_train.label.isin(other_df.label)]\n",
    "\n",
    "df_linear_1= df_linear.reset_index()\n",
    "df_linear_1['statement'] = df_linear_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'\n",
    "\n",
    "df_test = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df_1 = pd.DataFrame({\"label\": labels})\n",
    "\n",
    "df_linear_test = df_test[df_test.label.isin(other_df_1.label)]\n",
    "\n",
    "df_linear_test_1= df_linear_test.reset_index()\n",
    "df_linear_test_1['statement'] = df_linear_test_1['statement'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear_1['tokenized_statement'] = df_linear_1.apply(lambda row: nltk.word_tokenize(row['statement']), axis=1)\n",
    "df_linear_test_1['tokenized_statement'] = df_linear_test_1.apply(lambda row: nltk.word_tokenize(row['statement']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a vocab \n",
    "\n",
    "#all the unique words in a dataset \n",
    "word_set = set()\n",
    "\n",
    "for idx, row in df_linear_1.iterrows():\n",
    "    word_set.update(row['tokenized_statement'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a look up table \n",
    "vocab = {word:idx for idx,word in enumerate(word_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_zeros_needed = len(vocab)\n",
    "\n",
    "label_dict= {}\n",
    "\n",
    "for i in labels: \n",
    "\n",
    "    label_dict[i]= LabelClass(i,number_of_zeros_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true': <__main__.LabelClass object at 0x7f18782113a0>, 'false': <__main__.LabelClass object at 0x7f1878211280>, 'half-true': <__main__.LabelClass object at 0x7f18782b5be0>, 'barely-true': <__main__.LabelClass object at 0x7f187824beb0>}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_generator(sequence_toekns, vocab): \n",
    "\n",
    "    return_vector= np.zeros(number_of_zeros_needed)\n",
    "\n",
    "    #set some positions within that vector \n",
    "    for token in  sequence_toekns: \n",
    "        pos = vocab.get(token)\n",
    "        if pos is not None:\n",
    "            return_vector[pos] +=1\n",
    "\n",
    "\n",
    "\n",
    "    return(return_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_perceptron(df_train, df_test):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while count<180000:\n",
    "\n",
    "        df_train_sample= df_train.sample()\n",
    "\n",
    "        #get us the lable \n",
    "        actual_label = df_train_sample[\"label\"].iat[0]\n",
    "\n",
    "        #one hot vector for sentence \n",
    "        x_vector= vector_generator(df_train_sample[\"tokenized_statement\"].iat[0],vocab)\n",
    "\n",
    "        #To James- why the .dot operation?? \n",
    "\n",
    "        #for i in range(len(theta)):\n",
    "\n",
    "        #calc scores for algo \n",
    "\n",
    "        label_scores = []\n",
    "\n",
    "        #this is new \n",
    "        for label in labels:\n",
    "            #label_obj is the obj from that dict \n",
    "            label_obj = label_dict[label]\n",
    "\n",
    "            #    def calc_score(self, x_vector):\n",
    "            #        return np.dot(x_vector, self.theta) \n",
    "\n",
    "            label_scores.append(label_obj.calc_score(x_vector))\n",
    "\n",
    "        #this really is just getting the index for the highest score \n",
    "        max_score_index = np.argmax(label_scores)\n",
    "\n",
    "        #to figure out which label it really is \n",
    "        predicted_label = labels[max_score_index]\n",
    "\n",
    "\n",
    "        # predicted_label = \"true\" if theta_true_in_loop >= theta_false_in_loop else \"false\"\n",
    "\n",
    "        if actual_label != predicted_label:\n",
    "\n",
    "\n",
    "            #this is the same thing \n",
    "            for label_obj in label_dict.values():\n",
    "                #this is where that TRUE/FALSE return function within the Labelclass comes in \n",
    "                if label_obj.is_label(actual_label):\n",
    "                    label_obj.theta += x_vector\n",
    "                else:\n",
    "                    label_obj.theta -= x_vector\n",
    "\n",
    "\n",
    "        #add theta to your total obj\n",
    "        for label_obj in label_dict.values():\n",
    "            label_obj.update_running_total()\n",
    "        count+=1 \n",
    "\n",
    "    #this is a python syntax \n",
    "    for label_obj in label_dict.values():\n",
    "        label_obj.calc_avg_weight(count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_perceptron(df_linear_1, df_linear_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7788681274364834\n"
     ]
    }
   ],
   "source": [
    "df_test = df_linear_test_1\n",
    "\n",
    "to_calc =[]\n",
    "\n",
    "\n",
    "for i,row in df_test.iterrows():\n",
    "\n",
    "    #get us the lable \n",
    "    actual_label = row[\"label\"]\n",
    "\n",
    "    #one hot vector for sentence \n",
    "    x_vector= vector_generator(row[\"tokenized_statement\"],vocab)\n",
    "\n",
    "################################################################################3\n",
    "    #for i in range(len(theta)):\n",
    "\n",
    "    #calc scores for algo \n",
    "    label_scores = []\n",
    "\n",
    "    #this is new \n",
    "    for label in labels:\n",
    "        \n",
    "        label_obj = label_dict[label]\n",
    "\n",
    "        label_scores.append(label_obj.calc_test_score(x_vector))\n",
    "\n",
    "    max_score_index = np.argmax(label_scores)\n",
    "    predicted_label = labels[max_score_index]\n",
    "\n",
    "\n",
    "########################################################################################3\n",
    "    #this is to calc accurracy later \n",
    "    if predicted_label == row[\"label\"]: \n",
    "        to_calc.append(1)\n",
    "    else: \n",
    "        to_calc.append(0)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "count_correct = to_calc.count(1)\n",
    "rows_count = df_linear_test_1.shape[0]\n",
    "accuracy = count_correct/rows_count\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed8a150d7d37ab663d3aba4c202cca1b056a70e46f6886df0072485b153cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
