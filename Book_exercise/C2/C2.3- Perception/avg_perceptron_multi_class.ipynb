{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label class \n",
    "\n",
    "#theta\n",
    "#theta_training_in_loop\n",
    "#theta_testing_in_loop\n",
    "#avg_weight\n",
    "\n",
    "################################\n",
    "#a function here on old code line 38 \n",
    "\n",
    "#for testing part- line 22. turn that into an argmax to generate \n",
    "# predicted label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3414117625.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [14]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def is_label(self, label):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class LabelClass:\n",
    "    def __init__(self, label , number_of_zeros_needed):\n",
    "        self.label= label \n",
    "        self.number_of_zeros_needed= number_of_zeros_needed\n",
    "\n",
    "        self.theta = np.zeros(number_of_zeros_needed)\n",
    "        self.running_total = np.zeros(number_of_zeros_needed)\n",
    "\n",
    "    def calc_score(self, x_vector):\n",
    "        return np.dot(x_vector, self.theta) \n",
    "    \n",
    "    def running_total(self):\n",
    "        self.running_total+=self.theta\n",
    "    \n",
    "    def calc_avg_weight(self, count):\n",
    "        return self.running_total/count\n",
    "\n",
    "    def is_label(self, label):\n",
    "        return self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_train  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'\n",
    "\n",
    "df_train = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "labels= ['true', \"false\", \"half-true\", \"barely-true\"]\n",
    "other_df = pd.DataFrame({\"label\": labels})\n",
    "\n",
    "df_linear = df_train[df_train.label.isin(other_df.label)]\n",
    "\n",
    "df_linear_1= df_linear.reset_index()\n",
    "df_linear_1['statement'] = df_linear_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'\n",
    "\n",
    "df_test = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df_1 = pd.DataFrame({\"label\": labels})\n",
    "\n",
    "df_linear_test = df_test[df_test.label.isin(other_df_1.label)]\n",
    "\n",
    "df_linear_test_1= df_linear_test.reset_index()\n",
    "df_linear_test_1['statement'] = df_linear_test_1['statement'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear_1['tokenized_statement'] = df_linear_1.apply(lambda row: nltk.word_tokenize(row['statement']), axis=1)\n",
    "df_linear_test_1['tokenized_statement'] = df_linear_test_1.apply(lambda row: nltk.word_tokenize(row['statement']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a vocab \n",
    "\n",
    "#all the unique words in a dataset \n",
    "word_set = set()\n",
    "\n",
    "for idx, row in df_linear_1.iterrows():\n",
    "    word_set.update(row['tokenized_statement'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a look up table \n",
    "vocab = {word:idx for idx,word in enumerate(word_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_zeros_needed = len(vocab)\n",
    "\n",
    "label_dict= {}\n",
    "\n",
    "for i in labels: \n",
    "\n",
    "    label_dict[i]= LabelClass(i,number_of_zeros_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_generator(sequence_toekns, vocab): \n",
    "\n",
    "    return_vector= np.zeros(number_of_zeros_needed)\n",
    "\n",
    "    #set some positions within that vector \n",
    "    for token in  sequence_toekns: \n",
    "        pos = vocab.get(token)\n",
    "        if pos is not None:\n",
    "            return_vector[pos] +=1\n",
    "\n",
    "\n",
    "\n",
    "    return(return_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_perceptron(df_train, df_test):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while count<100:\n",
    "\n",
    "        df_train_sample= df_train.sample()\n",
    "\n",
    "        #get us the lable \n",
    "        actual_label = df_train_sample[\"label\"].iat[0]\n",
    "\n",
    "        #one hot vector for sentence \n",
    "        x_vector= vector_generator(df_train_sample[\"tokenized_statement\"].iat[0],vocab)\n",
    "\n",
    "        #To James- why the .dot operation?? \n",
    "\n",
    "        #for i in range(len(theta)):\n",
    "\n",
    "        #calc scores for algo \n",
    "\n",
    "        label_scores = []\n",
    "        for label in labels:\n",
    "            label_scores.append(label_dict[label].calc_score(x_vector))\n",
    "        max_score_index = np.argmax(label_scores)\n",
    "        predicted_label = labels[max_score_index]\n",
    "\n",
    "\n",
    "        # predicted_label = \"true\" if theta_true_in_loop >= theta_false_in_loop else \"false\"\n",
    "\n",
    "        if actual_label != predicted_label:\n",
    "\n",
    "            print(\"wrong\")\n",
    "            for label_obj in label_dict:\n",
    "                \n",
    "            #To James- need more explanation on this part \n",
    "            if actual_label == \"false\":\n",
    "                \n",
    "                #34:08 \n",
    "                #penalize if mistake and encourage if right \n",
    "                #we want theta false to go higher \n",
    "\n",
    "                theta_false = theta_false +x_vector #I want the actual label to have more weight on those words \n",
    "                theta_true = theta_true -x_vector \n",
    "            else: \n",
    "                theta_false = theta_false -x_vector \n",
    "                theta_true = theta_true +x_vector \n",
    "        else:\n",
    "            print(\"right\")\n",
    "\n",
    "        avg_weight_true += theta_true\n",
    "        avg_weight_false+= theta_false\n",
    "\n",
    "        \n",
    "        count+=1 \n",
    "\n",
    "\n",
    "    return avg_weight_true/count, avg_weight_false/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "avg_weight_true,avg_weight_false= avg_perceptron(df_linear_1, df_linear_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5538000544810678\n"
     ]
    }
   ],
   "source": [
    "df_test = df_linear_test_1\n",
    "\n",
    "to_calc =[]\n",
    "\n",
    "\n",
    "for i,row in df_test.iterrows():\n",
    "\n",
    "    #get us the lable \n",
    "    actual_label = row[\"label\"]\n",
    "\n",
    "    #one hot vector for sentence \n",
    "    x_vector= vector_generator(row[\"tokenized_statement\"],vocab)\n",
    "\n",
    "    #To James- why the .dot operation?? \n",
    "\n",
    "    #for i in range(len(theta)):\n",
    "\n",
    "    #calc scores for algo \n",
    "    theta_true_in_loop = np.dot(x_vector, avg_weight_true ) #averaged weight\n",
    "    theta_false_in_loop= np.dot(x_vector, avg_weight_false)\n",
    "\n",
    "    predicted_label = \"true\" if theta_true_in_loop >= theta_false_in_loop else \"false\"\n",
    "\n",
    "    #this is to calc accurracy later \n",
    "    if predicted_label == row[\"label\"]: \n",
    "        to_calc.append(1)\n",
    "    else: \n",
    "        to_calc.append(0)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "count_correct = to_calc.count(1)\n",
    "rows_count = df_linear_test_1.shape[0]\n",
    "accuracy = count_correct/rows_count\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed8a150d7d37ab663d3aba4c202cca1b056a70e46f6886df0072485b153cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
