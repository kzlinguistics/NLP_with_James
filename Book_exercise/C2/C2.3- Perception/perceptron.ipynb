{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_train  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'\n",
    "\n",
    "df_train = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df = pd.DataFrame({\"label\": ['true', \"false\"]})\n",
    "\n",
    "df_linear = df_train[df_train.label.isin(other_df.label)]\n",
    "\n",
    "df_linear_1= df_linear.reset_index()\n",
    "df_linear_1['statement'] = df_linear_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'\n",
    "\n",
    "df_test = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df_1 = pd.DataFrame({\"label\": ['true', \"false\"]})\n",
    "\n",
    "df_linear_test = df_test[df_test.label.isin(other_df_1.label)]\n",
    "\n",
    "df_linear_test_1= df_linear_test.reset_index()\n",
    "df_linear_test_1['statement'] = df_linear_test_1['statement'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the perceptron algorithm, what we do is we continuously sample again and again, you pick an item at random from that data frame. See if it's right or wrong, make an update, pick another item. Then pick another one pick another one pick another one, and so on, keep making changes until the model converges. So there's no specific order we should be sampling or picking them. So we could we could pick all of them one time by calling the SROs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- tokenize all the input \n",
    "2- we need a feature vector for every item \n",
    "3- need to intiatialize our theta to be 0\n",
    "    3.1- the size of the theta needs to be the same size of the vocab \n",
    "    -|\\theta| = |V|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear_1['tokenized_statement'] = df_linear_1.apply(lambda row: nltk.word_tokenize(row['statement']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a vocab \n",
    "\n",
    "#all the unique words in a dataset \n",
    "word_set = set()\n",
    "\n",
    "for idx, row in df_linear_1.iterrows():\n",
    "    word_set.update(row['tokenized_statement'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a look up table \n",
    "vocab = {word:idx for idx,word in enumerate(word_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_zeros_needed = len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_generator(sequence_toekns, vocab): \n",
    "\n",
    "    return_vector= np.zeros(number_of_zeros_needed)\n",
    "\n",
    "    #set some positions within that vector \n",
    "    for token in  sequence_toekns: \n",
    "        pos = vocab.get(token)\n",
    "        if pos is not None:\n",
    "            return_vector[pos] +=1\n",
    "\n",
    "\n",
    "\n",
    "    return(return_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(df_train, df_test):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    theta_true= np.zeros(number_of_zeros_needed)\n",
    "    theta_false= np.zeros(number_of_zeros_needed)\n",
    "     \n",
    "    while count<100:\n",
    "\n",
    "        df_train_sample= df_train.sample()\n",
    "\n",
    "        actual_label = df_train_sample[\"label\"].iat[0]\n",
    "        x_vector= vector_generator(df_train_sample[\"tokenized_statement\"].iat[0],vocab)\n",
    "\n",
    "        #why the .dot operation \n",
    "        theta_true_in_loop = np.dot(x_vector,theta_true)\n",
    "        theta_false_in_loop= np.dot(x_vector,theta_false)\n",
    "\n",
    "        predicted_label = \"true\" if theta_true_in_loop >= theta_false_in_loop else \"false\"\n",
    "\n",
    "        if actual_label != predicted_label:\n",
    "\n",
    "            print(\"wrong\")\n",
    "\n",
    "            if actual_label == \"false\":\n",
    "\n",
    "                theta_false = theta_false +x_vector \n",
    "                theta_true = theta_true -x_vector \n",
    "\n",
    "            else: \n",
    "                theta_false = theta_false -x_vector \n",
    "                theta_true = theta_true +x_vector \n",
    "        else:\n",
    "            print(\"right\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        count+=1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "wrong\n",
      "right\n",
      "wrong\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n",
      "right\n"
     ]
    }
   ],
   "source": [
    "perceptron(df_linear_1, df_linear_test_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed8a150d7d37ab663d3aba4c202cca1b056a70e46f6886df0072485b153cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
