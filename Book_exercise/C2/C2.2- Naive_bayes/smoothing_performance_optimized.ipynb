{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#things associated with a label \n",
    "\n",
    "1- counter \n",
    "2- probability \n",
    "3- function for individual probability \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so when you create a class, you're not defining an object you're defining like something that that tells the operating length or the language that you're working in, what objects of this type look like. So for us objects of this type have a counter objects of this type have a probability and object of this type have a certain handful of functions associated with them. And, and that's what we'll go sort of capture in this in this in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelClass: \n",
    "    def __init__(self, label):\n",
    "        self.counter= collections.Counter()\n",
    "        self.label= label \n",
    "\n",
    "    def calc_prob(self, alpha):\n",
    "        self.probs = {key: (alpha + value) / (sum(self.counter.values()) + (alpha * len(self.counter))) for key, value in self.counter.items()}\n",
    "\n",
    "    def calc_prob_sen(self, sentence, label_prob):\n",
    "        return math.prod([self.probs.get(word,0) for word in sentence])*label_prob[self.label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_train  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'\n",
    "\n",
    "df_train = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "\n",
    "labels= ['true', \"false\", \"half-true\", \"barely-true\"]\n",
    "other_df = pd.DataFrame({\"label\": labels})\n",
    "\n",
    "df_linear = df_train[df_train.label.isin(other_df.label)]\n",
    "\n",
    "df_linear_1= df_linear.reset_index()\n",
    "df_linear_1['statement'] = df_linear_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()\n",
    "\n",
    "label_dict= {}\n",
    "\n",
    "for i in labels: \n",
    "\n",
    "    label_dict[i]= LabelClass(i)\n",
    "\n",
    "#print(label_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'\n",
    "\n",
    "df_test = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df_1 = pd.DataFrame({\"label\": ['true', \"false\", \"half-true\", \"barely-true\"]})\n",
    "\n",
    "df_linear_test = df_test[df_test.label.isin(other_df_1.label)]\n",
    "\n",
    "df_linear_test_1= df_linear_test.reset_index()\n",
    "df_linear_test_1['statement'] = df_linear_test_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_alpha(train_df, test_df, alpha: int): \n",
    "\n",
    "    df_linear_1 = train_df\n",
    "    df_linear_test_1 = test_df\n",
    "\n",
    "    ###################################################################\n",
    "    label_cnt = collections.Counter(df_linear_1.label)\n",
    "    # true_cnt = collections.Counter() #true_cnt is p(x|true)\n",
    "    # false_cnt = collections.Counter()\n",
    "    # half_true_cnt= collections.Counter()\n",
    "    # barely_true_cnt= collections.Counter()\n",
    "\n",
    "\n",
    "\n",
    "    for idx, row in df_linear_1.iterrows():\n",
    "\n",
    "        counter= label_dict[row[\"label\"]].counter()\n",
    "        counter.update(row[\"statement\"].split())\n",
    "\n",
    "\n",
    "    ################################################################### \n",
    "    label_probs = {key: value / sum(label_cnt.values()) for key, value in label_cnt.items()}\n",
    "\n",
    "    for key, value in label_dict:\n",
    "        value.calc_probs(alpha)\n",
    "\n",
    "    ##############L####################################################\n",
    "\n",
    "    to_calc =[]\n",
    "\n",
    "    for idx, row in df_linear_test_1.iterrows(): \n",
    "\n",
    "        sentence = row[\"statement\"].split() \n",
    "        label_arr = label_dict.keys()\n",
    "        prob_arr = []\n",
    "        for key, value in label_dict:\n",
    "            prob_arr.push(value.calc_prob_sen(sentence, label_probs))\n",
    "        # probability_matrix = np.array([label_arr, prob_arr])\n",
    "        max_prob_index = np.argmax(prob_arr)\n",
    "        max_prob_label = label_arr[max_prob_index]\n",
    "        curr_probs = max_prob_label\n",
    "\n",
    "\n",
    "        #this is to calc accurracy later \n",
    "        if curr_probs == row[\"label\"]: \n",
    "            to_calc.append(1)\n",
    "        else: \n",
    "            to_calc.append(0)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    count_correct = to_calc.count(1)\n",
    "    rows_count = df_linear_test_1.shape[0]\n",
    "    accuracy = count_correct/rows_count\n",
    "\n",
    "\n",
    "\n",
    "    return(accuracy) \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LabelClass' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2- Naive_bayes/smoothing_performance_optimized.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2-%20Naive_bayes/smoothing_performance_optimized.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m naive_bayes_alpha(df_linear_1, df_linear_test_1, \u001b[39m0.5\u001b[39;49m)\n",
      "\u001b[1;32m/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2- Naive_bayes/smoothing_performance_optimized.ipynb Cell 8\u001b[0m in \u001b[0;36mnaive_bayes_alpha\u001b[0;34m(train_df, test_df, alpha)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2-%20Naive_bayes/smoothing_performance_optimized.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m df_linear_1\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2-%20Naive_bayes/smoothing_performance_optimized.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     counter\u001b[39m=\u001b[39m label_dict[row[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2-%20Naive_bayes/smoothing_performance_optimized.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     counter\u001b[39m.\u001b[39;49mupdate(row[\u001b[39m\"\u001b[39m\u001b[39mstatement\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msplit())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2-%20Naive_bayes/smoothing_performance_optimized.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m################################################################### \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kevin/Documents/NLP_with_James/Book_exercise/C2/C2.2-%20Naive_bayes/smoothing_performance_optimized.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m label_probs \u001b[39m=\u001b[39m {key: value \u001b[39m/\u001b[39m \u001b[39msum\u001b[39m(label_cnt\u001b[39m.\u001b[39mvalues()) \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m label_cnt\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LabelClass' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "naive_bayes_alpha(df_linear_1, df_linear_test_1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "empt_list= []\n",
    "\n",
    "for i in range(100): \n",
    "\n",
    "    curr_accurange= naive_bayes_alpha(df_linear_1, df_linear_test_1, i)\n",
    "\n",
    "    curr_list= [i,curr_accurange]\n",
    "\n",
    "    empt_list.append(curr_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing has not helped. the accuracy keeps on dropping \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed8a150d7d37ab663d3aba4c202cca1b056a70e46f6886df0072485b153cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
