{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_train  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/train.tsv'\n",
    "\n",
    "df_train = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df = pd.DataFrame({\"label\": ['true', \"false\", \"half-true\", \"barely-true\"]})\n",
    "\n",
    "df_linear = df_train[df_train.label.isin(other_df.label)]\n",
    "\n",
    "df_linear_1= df_linear.reset_index()\n",
    "df_linear_1['statement'] = df_linear_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_test  = 'https://raw.githubusercontent.com/thiagorainmaker77/liar_dataset/master/test.tsv'\n",
    "\n",
    "df_test = pd.read_table(uri_train,\n",
    "                             names = ['id',\t'label'\t,'statement',\t'subject',\t'speaker', \t'job', \t'state',\t'party',\t'barely_true_c',\t'false_c',\t'half_true_c',\t'mostly_true_c',\t'pants_on_fire_c',\t'venue'])\n",
    "\n",
    "other_df_1 = pd.DataFrame({\"label\": ['true', \"false\", \"half-true\", \"barely-true\"]})\n",
    "\n",
    "df_linear_test = df_test[df_test.label.isin(other_df_1.label)]\n",
    "\n",
    "df_linear_test_1= df_linear_test.reset_index()\n",
    "df_linear_test_1['statement'] = df_linear_test_1['statement'].str.lower()\n",
    "#df_linear_1['statement']= df_linear_1['statement'].str.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_alpha(train_df, test_df, alpha: int): \n",
    "\n",
    "    df_linear_1 = train_df\n",
    "    df_linear_test_1 = test_df\n",
    "\n",
    "    ###################################################################\n",
    "    label_cnt = collections.Counter(df_linear_1.label)\n",
    "    true_cnt = collections.Counter() #true_cnt is p(x|true)\n",
    "    false_cnt = collections.Counter()\n",
    "    half_true_cnt= collections.Counter()\n",
    "    barely_true_cnt= collections.Counter()\n",
    "\n",
    "\n",
    "\n",
    "    for idx, row in df_linear_1.iterrows():\n",
    "\n",
    "        if row[\"label\"]== \"true\":\n",
    "\n",
    "            true_cnt.update(row[\"statement\"].split())\n",
    "\n",
    "        if row[\"label\"]== \"false\":\n",
    "\n",
    "            false_cnt.update(row[\"statement\"].split())\n",
    "\n",
    "        if row[\"label\"]== \"half-true\":\n",
    "\n",
    "            half_true_cnt.update(row[\"statement\"].split())\n",
    "\n",
    "        if row[\"label\"]== \"barely-true\":\n",
    "\n",
    "            barely_true_cnt.update(row[\"statement\"].split())\n",
    "\n",
    "    ################################################################### \n",
    "    label_probs = {key: value / sum(label_cnt.values()) for key, value in label_cnt.items()}\n",
    "    true_probs = {key: (alpha + value) / (sum(true_cnt.values()) + (alpha * len(true_cnt))) for key, value in true_cnt.items()}\n",
    "    false_probs = {key: (alpha + value) / (sum(false_cnt.values()) + (alpha * len(false_cnt))) for key, value in false_cnt.items()}\n",
    "    half_true_probs = {key: (alpha + value) / (sum(half_true_cnt.values()) + (alpha * len(half_true_cnt))) for key, value in half_true_cnt.items()}\n",
    "    barely_true_probs = {key: (alpha + value) / (sum(barely_true_cnt.values()) + (alpha * len(barely_true_cnt))) for key, value in barely_true_cnt.items()}\n",
    "\n",
    "        ##################################################################\n",
    "\n",
    "    to_calc =[]\n",
    "\n",
    "    for idx, row in df_linear_test_1.iterrows(): \n",
    "\n",
    "        sentence = row[\"statement\"].split() \n",
    "\n",
    "        true_prob = math.prod([true_probs.get(word,0) for word in sentence])*label_probs[\"true\"]\n",
    "        false_prob = math.prod([false_probs.get(word,0) for word in sentence])*label_probs[\"false\"]\n",
    "        half_true_prob= math.prod([half_true_probs.get(word,0) for word in sentence])*label_probs[\"half-true\"]\n",
    "        barely_true_prob= math.prod([barely_true_probs.get(word,0) for word in sentence])*label_probs[\"barely-true\"]\n",
    "\n",
    "\n",
    "        if true_prob > false_prob: \n",
    "            curr_probs = \"true\"\n",
    "        elif true_prob > half_true_prob: \n",
    "            curr_probs = \"true\"\n",
    "        elif true_prob > barely_true_prob: \n",
    "            curr_probs = \"true\"\n",
    "        elif half_true_prob> false_prob: \n",
    "            curr_probs = \"half-true\"\n",
    "        elif half_true_prob> true_prob: \n",
    "            curr_probs = \"half-true\"\n",
    "        elif half_true_prob> barely_true_prob: \n",
    "            curr_probs = \"half-true\"\n",
    "        elif barely_true_prob> half_true_prob: \n",
    "            curr_probs = \"barely-true\"\n",
    "        elif barely_true_prob> false_prob: \n",
    "            curr_probs = \"barely-true\"\n",
    "        elif barely_true_prob> true_prob: \n",
    "            curr_probs = \"barely-true\"\n",
    "        else: \n",
    "            curr_probs = \"false\"\n",
    "\n",
    "        #this is to calc accurracy later \n",
    "        if curr_probs == row[\"label\"]: \n",
    "            to_calc.append(1)\n",
    "        else: \n",
    "            to_calc.append(0)\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    count_correct = to_calc.count(1)\n",
    "    rows_count = df_linear_test_1.shape[0]\n",
    "    accuracy = count_correct/rows_count\n",
    "\n",
    "\n",
    "\n",
    "    return(accuracy) \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634225030246001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_alpha(df_linear_1, df_linear_test_1, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "empt_list= []\n",
    "\n",
    "for i in range(100): \n",
    "\n",
    "    curr_accurange= naive_bayes_alpha(df_linear_1, df_linear_test_1, i)\n",
    "\n",
    "    curr_list= [i,curr_accurange]\n",
    "\n",
    "    empt_list.append(curr_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.8667831697808845],\n",
       " [1, 0.8661110364296276],\n",
       " [2, 0.8663798897701304],\n",
       " [3, 0.866245463099879],\n",
       " [4, 0.8658421830891249],\n",
       " [5, 0.8657077564188735],\n",
       " [6, 0.8654389030783708],\n",
       " [7, 0.8655733297486221],\n",
       " [8, 0.8654389030783708],\n",
       " [9, 0.8655733297486221],\n",
       " [10, 0.8653044764081194],\n",
       " [11, 0.865170049737868],\n",
       " [12, 0.865170049737868],\n",
       " [13, 0.8649011963973653],\n",
       " [14, 0.8650356230676166],\n",
       " [15, 0.8650356230676166],\n",
       " [16, 0.8649011963973653],\n",
       " [17, 0.8647667697271139],\n",
       " [18, 0.8647667697271139],\n",
       " [19, 0.8647667697271139],\n",
       " [20, 0.8647667697271139],\n",
       " [21, 0.8647667697271139],\n",
       " [22, 0.8647667697271139],\n",
       " [23, 0.8647667697271139],\n",
       " [24, 0.8647667697271139],\n",
       " [25, 0.8646323430568624],\n",
       " [26, 0.8646323430568624],\n",
       " [27, 0.8646323430568624],\n",
       " [28, 0.8646323430568624],\n",
       " [29, 0.8646323430568624],\n",
       " [30, 0.8646323430568624],\n",
       " [31, 0.8646323430568624],\n",
       " [32, 0.8646323430568624],\n",
       " [33, 0.8647667697271139],\n",
       " [34, 0.8647667697271139],\n",
       " [35, 0.8647667697271139],\n",
       " [36, 0.8647667697271139],\n",
       " [37, 0.8647667697271139],\n",
       " [38, 0.8647667697271139],\n",
       " [39, 0.8647667697271139],\n",
       " [40, 0.8646323430568624],\n",
       " [41, 0.8644979163866111],\n",
       " [42, 0.8644979163866111],\n",
       " [43, 0.8644979163866111],\n",
       " [44, 0.8644979163866111],\n",
       " [45, 0.8644979163866111],\n",
       " [46, 0.8643634897163597],\n",
       " [47, 0.8643634897163597],\n",
       " [48, 0.8643634897163597],\n",
       " [49, 0.8643634897163597],\n",
       " [50, 0.8643634897163597],\n",
       " [51, 0.8644979163866111],\n",
       " [52, 0.8644979163866111],\n",
       " [53, 0.8646323430568624],\n",
       " [54, 0.8646323430568624],\n",
       " [55, 0.8647667697271139],\n",
       " [56, 0.8649011963973653],\n",
       " [57, 0.8649011963973653],\n",
       " [58, 0.865170049737868],\n",
       " [59, 0.8653044764081194],\n",
       " [60, 0.8653044764081194],\n",
       " [61, 0.8653044764081194],\n",
       " [62, 0.8653044764081194],\n",
       " [63, 0.865170049737868],\n",
       " [64, 0.865170049737868],\n",
       " [65, 0.865170049737868],\n",
       " [66, 0.865170049737868],\n",
       " [67, 0.865170049737868],\n",
       " [68, 0.865170049737868],\n",
       " [69, 0.865170049737868],\n",
       " [70, 0.865170049737868],\n",
       " [71, 0.865170049737868],\n",
       " [72, 0.865170049737868],\n",
       " [73, 0.8650356230676166],\n",
       " [74, 0.8650356230676166],\n",
       " [75, 0.8649011963973653],\n",
       " [76, 0.8649011963973653],\n",
       " [77, 0.8649011963973653],\n",
       " [78, 0.8647667697271139],\n",
       " [79, 0.8647667697271139],\n",
       " [80, 0.8647667697271139],\n",
       " [81, 0.8647667697271139],\n",
       " [82, 0.8647667697271139],\n",
       " [83, 0.8646323430568624],\n",
       " [84, 0.8646323430568624],\n",
       " [85, 0.8646323430568624],\n",
       " [86, 0.8646323430568624],\n",
       " [87, 0.8646323430568624],\n",
       " [88, 0.8644979163866111],\n",
       " [89, 0.8644979163866111],\n",
       " [90, 0.8644979163866111],\n",
       " [91, 0.8644979163866111],\n",
       " [92, 0.8644979163866111],\n",
       " [93, 0.8644979163866111],\n",
       " [94, 0.8643634897163597],\n",
       " [95, 0.8643634897163597],\n",
       " [96, 0.8643634897163597],\n",
       " [97, 0.8643634897163597],\n",
       " [98, 0.8643634897163597],\n",
       " [99, 0.8643634897163597]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing has not helped. the accuracy keeps on dropping \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58ed8a150d7d37ab663d3aba4c202cca1b056a70e46f6886df0072485b153cf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
