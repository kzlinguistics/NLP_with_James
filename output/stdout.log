2022-07-28 21:59:47,470 - INFO - allennlp.common.params - random_seed = 13370
2022-07-28 21:59:47,470 - INFO - allennlp.common.params - numpy_seed = 1337
2022-07-28 21:59:47,470 - INFO - allennlp.common.params - pytorch_seed = 133
2022-07-28 21:59:47,470 - INFO - allennlp.common.checks - Pytorch version: 1.4.0
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - type = default
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - dataset_reader.type = snli
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - dataset_reader.lazy = False
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - dataset_reader.cache_directory = None
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - dataset_reader.max_instances = None
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - dataset_reader.tokenizer = None
2022-07-28 21:59:47,471 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2022-07-28 21:59:47,472 - INFO - allennlp.common.params - dataset_reader.combine_input_fields = None
2022-07-28 21:59:47,964 - INFO - allennlp.common.params - train_data_path = https://s3-us-west-2.amazonaws.com/allennlp/datasets/snli/snli_1.0_dev.jsonl
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - vocabulary = None
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - validation_dataset_reader = None
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - validation_data_path = https://s3-us-west-2.amazonaws.com/allennlp/datasets/snli/snli_1.0_dev.jsonl
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - validation_data_loader = None
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - test_data_path = None
2022-07-28 21:59:47,965 - INFO - allennlp.common.params - evaluate_on_test = False
2022-07-28 21:59:47,965 - INFO - allennlp.training.util - Reading training data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/snli/snli_1.0_dev.jsonl
2022-07-28 21:59:48,294 - INFO - allennlp.data.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/kevin/.allennlp/cache/d62e9805c21b0d8bc720ed5484b4907bbf740a2fe3351c8f41583822a54fbb76.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687
2022-07-28 21:59:50,694 - INFO - allennlp.training.util - Reading validation data from https://s3-us-west-2.amazonaws.com/allennlp/datasets/snli/snli_1.0_dev.jsonl
2022-07-28 21:59:51,021 - INFO - allennlp.data.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: /home/kevin/.allennlp/cache/d62e9805c21b0d8bc720ed5484b4907bbf740a2fe3351c8f41583822a54fbb76.07ccd1720fbe07137833cd627398fb7e2687bdcbad963d71cae8c97a37f76687
2022-07-28 21:59:53,044 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2022-07-28 21:59:53,374 - INFO - allennlp.common.params - model.type = kevin_mod
2022-07-28 21:59:53,374 - INFO - allennlp.common.params - model.hidden_dim = 100
2022-07-28 21:59:53,374 - INFO - allennlp.common.params - model.text_field_embedder.type = basic
2022-07-28 21:59:53,374 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = 100
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.weight = None
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = False
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens
2022-07-28 21:59:53,375 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = https://allennlp.s3.amazonaws.com/datasets/glove/glove.840B.300d.txt.gz
2022-07-28 21:59:53,375 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file
2022-07-28 22:00:34,974 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer
2022-07-28 22:00:35,045 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 6259 out of 6316 tokens
2022-07-28 22:00:35,048 - INFO - allennlp.common.params - model.initializer.regexes.0.1.type = xavier_normal
2022-07-28 22:00:35,048 - INFO - allennlp.common.params - model.initializer.regexes.0.1.gain = 1.0
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.initializer.regexes.1.1.type = xavier_normal
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.initializer.regexes.1.1.gain = 1.0
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.initializer.prevent_regexes = None
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.num_layers = 2
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.bidirectional = True
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.dropout_rate = 0.0
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.num_classification = 3
2022-07-28 22:00:35,049 - INFO - allennlp.common.params - model.regularizer = None
2022-07-28 22:00:35,049 - INFO - allennlp.nn.initializers - Initializing parameters
2022-07-28 22:00:35,050 - INFO - allennlp.nn.initializers - Initializing _text_field_embedder.token_embedder_tokens._projection.weight using .*token_embedder_tokens\._projection.*weight initializer
2022-07-28 22:00:35,050 - WARNING - allennlp.nn.initializers - Did not use initialization regex that was passed: .*linear_layers.*weight
2022-07-28 22:00:35,050 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2022-07-28 22:00:35,052 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens._projection.bias
2022-07-28 22:00:35,052 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight
2022-07-28 22:00:35,069 - INFO - allennlp.common.params - data_loader.type = default
2022-07-28 22:00:35,069 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-07-28 22:00:35,069 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-07-28 22:00:35,069 - INFO - allennlp.common.params - data_loader.sampler = None
2022-07-28 22:00:35,069 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 32
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.type = default
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.batch_size = 1
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.shuffle = False
2022-07-28 22:00:35,070 - INFO - allennlp.common.params - data_loader.sampler = None
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.num_workers = 0
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.pin_memory = False
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.drop_last = False
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.timeout = 0
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 32
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - trainer.type = gradient_descent
2022-07-28 22:00:35,071 - INFO - allennlp.common.params - trainer.patience = 5
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.validation_metric = +accuracy
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.num_epochs = 75
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.cuda_device = -1
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.grad_norm = 10
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.grad_clipping = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.distributed = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.world_size = 1
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.opt_level = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.no_grad = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.tensorboard_writer = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.moving_average = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.checkpointer = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2022-07-28 22:00:35,072 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2022-07-28 22:00:35,072 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.weight
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._projection.weight
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens._projection.bias
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_ih_l0
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_hh_l0
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_ih_l0
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_hh_l0
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_ih_l0_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_hh_l0_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_ih_l0_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_hh_l0_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_ih_l1
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_hh_l1
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_ih_l1
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_hh_l1
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_ih_l1_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.weight_hh_l1_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_ih_l1_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - LSTM.bias_hh_l1_reverse
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - fc.weight
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - fc.bias
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - fc2.weight
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - fc2.bias
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - fc3.weight
2022-07-28 22:00:35,073 - INFO - allennlp.common.util - fc3.bias
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0004
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2022-07-28 22:00:35,074 - INFO - allennlp.training.optimizers - Number of trainable parameters: 523803
2022-07-28 22:00:35,074 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = reduce_on_plateau
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.mode = max
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 0.5
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.patience = 0
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.verbose = False
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold_mode = rel
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold = 0.0001
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cooldown = 0
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.min_lr = 0
2022-07-28 22:00:35,075 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.eps = 1e-08
2022-07-28 22:00:35,078 - INFO - allennlp.training.trainer - Beginning training.
2022-07-28 22:00:35,078 - INFO - allennlp.training.trainer - Epoch 0/74
2022-07-28 22:00:35,078 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 590.0
2022-07-28 22:00:35,108 - INFO - allennlp.training.trainer - Training
2022-07-28 22:00:35,111 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-07-28 22:00:35,113 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['premise'] as the sorting keys
2022-07-28 22:01:53,981 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:01:53,981 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2022-07-28 22:01:53,982 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['premise'] as the sorting keys
2022-07-28 22:02:09,988 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2022-07-28 22:02:09,988 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |   590.000  |       N/A
2022-07-28 22:02:09,988 - INFO - allennlp.training.tensorboard_writer - loss          |     1.100  |     1.099
2022-07-28 22:02:09,988 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.336  |     0.327
2022-07-28 22:02:10,001 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'output/best.th'.
2022-07-28 22:02:10,010 - INFO - allennlp.training.trainer - Epoch duration: 0:01:34.932535
2022-07-28 22:02:10,011 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:57:05
2022-07-28 22:02:10,011 - INFO - allennlp.training.trainer - Epoch 1/74
2022-07-28 22:02:10,011 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 856.252
2022-07-28 22:02:10,061 - INFO - allennlp.training.trainer - Training
2022-07-28 22:03:29,987 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:03:46,668 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2022-07-28 22:03:46,668 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |   856.252  |       N/A
2022-07-28 22:03:46,669 - INFO - allennlp.training.tensorboard_writer - loss          |     1.099  |     1.099
2022-07-28 22:03:46,669 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.330  |     0.343
2022-07-28 22:03:46,683 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'output/best.th'.
2022-07-28 22:03:46,705 - INFO - allennlp.training.trainer - Epoch duration: 0:01:36.693440
2022-07-28 22:03:46,706 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:56:34
2022-07-28 22:03:46,706 - INFO - allennlp.training.trainer - Epoch 2/74
2022-07-28 22:03:46,706 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 937.604
2022-07-28 22:03:46,767 - INFO - allennlp.training.trainer - Training
2022-07-28 22:05:18,255 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:05:34,691 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2022-07-28 22:05:34,691 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |   937.604  |       N/A
2022-07-28 22:05:34,692 - INFO - allennlp.training.tensorboard_writer - loss          |     1.099  |     1.099
2022-07-28 22:05:34,692 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.333  |     0.329
2022-07-28 22:05:34,706 - INFO - allennlp.training.trainer - Epoch duration: 0:01:48.000308
2022-07-28 22:05:34,706 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:59:51
2022-07-28 22:05:34,706 - INFO - allennlp.training.trainer - Epoch 3/74
2022-07-28 22:05:34,706 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 951.34
2022-07-28 22:05:34,759 - INFO - allennlp.training.trainer - Training
2022-07-28 22:06:54,601 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:07:10,744 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2022-07-28 22:07:10,744 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |   951.340  |       N/A
2022-07-28 22:07:10,745 - INFO - allennlp.training.tensorboard_writer - loss          |     1.099  |     1.099
2022-07-28 22:07:10,745 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.333  |     0.339
2022-07-28 22:07:10,758 - INFO - allennlp.training.trainer - Epoch duration: 0:01:36.051975
2022-07-28 22:07:10,759 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:57:03
2022-07-28 22:07:10,759 - INFO - allennlp.training.trainer - Epoch 4/74
2022-07-28 22:07:10,759 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1085.008
2022-07-28 22:07:10,813 - INFO - allennlp.training.trainer - Training
2022-07-28 22:08:26,566 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:08:42,207 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2022-07-28 22:08:42,207 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1085.008  |       N/A
2022-07-28 22:08:42,207 - INFO - allennlp.training.tensorboard_writer - loss          |     1.099  |     1.099
2022-07-28 22:08:42,207 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.339  |     0.336
2022-07-28 22:08:42,222 - INFO - allennlp.training.trainer - Epoch duration: 0:01:31.463215
2022-07-28 22:08:42,222 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:53:40
2022-07-28 22:08:42,222 - INFO - allennlp.training.trainer - Epoch 5/74
2022-07-28 22:08:42,223 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1105.276
2022-07-28 22:08:42,276 - INFO - allennlp.training.trainer - Training
2022-07-28 22:09:58,775 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:10:14,373 - INFO - allennlp.training.tensorboard_writer -                   Training |  Validation
2022-07-28 22:10:14,373 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB |  1105.276  |       N/A
2022-07-28 22:10:14,374 - INFO - allennlp.training.tensorboard_writer - loss          |     1.099  |     1.099
2022-07-28 22:10:14,374 - INFO - allennlp.training.tensorboard_writer - accuracy      |     0.336  |     0.336
2022-07-28 22:10:14,388 - INFO - allennlp.training.trainer - Epoch duration: 0:01:32.165885
2022-07-28 22:10:14,389 - INFO - allennlp.training.trainer - Estimated training time remaining: 1:51:02
2022-07-28 22:10:14,389 - INFO - allennlp.training.trainer - Epoch 6/74
2022-07-28 22:10:14,389 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 1127.244
2022-07-28 22:10:14,445 - INFO - allennlp.training.trainer - Training
2022-07-28 22:11:30,854 - INFO - allennlp.training.trainer - Validating
2022-07-28 22:11:45,875 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2022-07-28 22:11:45,875 - INFO - allennlp.training.checkpointer - loading best weights
2022-07-28 22:11:45,883 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 1,
  "peak_cpu_memory_MB": 1127.244,
  "training_duration": "0:09:39.296211",
  "training_start_epoch": 0,
  "training_epochs": 5,
  "epoch": 5,
  "training_accuracy": 0.3362121520016257,
  "training_loss": 1.0987053145835926,
  "training_cpu_memory_MB": 1105.276,
  "validation_accuracy": 0.3364153627311522,
  "validation_loss": 1.0985794226070502,
  "best_validation_accuracy": 0.34261328998171103,
  "best_validation_loss": 1.0985583953269116
}
2022-07-28 22:11:45,883 - INFO - allennlp.models.archival - archiving weights and vocabulary to output/model.tar.gz
